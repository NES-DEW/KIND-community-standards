---
title: "R reading group notes"
date: "2024-09-26"
execute: 
  echo: true
  output: true
editor_options: 
  chunk_output_type: console
---

This was about the [names and values chapter in Advanced R (2nd ed)](https://adv-r.hadley.nz/names-values.html). It's mainly about understanding how objects are named in R, and what the implications are for ordinary R practitioners. 

```{r}
library(lobstr) # to help understand how objects are structured
library(dplyr)
library(microbenchmark)
```

The first point is about names. We usually think about assignment as making an object called `x`. But it's definitely better to think about these separately - first creating an object and then binding it to a name. That means that names have objects, rather than objects having names.

```{r}
x <- c(1, 2, 3) # create an object
obj_addr(x) # location in memory
y <- x # bind an additional name to the object
obj_addr(x) == obj_addr(y) # it's just one object with two names
```

This applies to objects in general, including function definitions:

```{r}
obj_addr(mean)
steve <- mean
obj_addr(steve)
```

We only create a new object when we modify one of the names:

```{r}
y[3] <- 9
obj_addr(x) == obj_addr(y) # different objects now
```

There are a couple of important exceptions to this general principle. First, lists have an extra step, in that they refer to references, rather than to objects directly:

```{r}
l1 <- list(1, 2, 3)
l2 <- l1

obj_addr(l1)
obj_addr(l2)

l2[[3]] <- 99

obj_addr(l1)
obj_addr(l2)

ref(l1, l2)
```

As tibbles (and other tabular data structures in R) are effectively lists, this is an explaination as to why row-wise operations are so slow compared to operations on columns. As tibbles are are lists of columns, updating a column just makes a new reference. Changing a row, on the other hand, makes a whole new set of objects and references:

```{r}
mt_changed_col <- mtcars
mt_changed_col$hp <- mtcars$hp*9

mt_changed_row <- mtcars
mt_changed_row[1,] <- mt_changed_row[1,] * 9

ref(mtcars, mt_changed_col, mt_changed_row)

col_row <- microbenchmark(
  {mt_changed_col <- mtcars
  mt_changed_col["hp"] <- mtcars["hp"]*9},
  
  {mt_changed_row <- mtcars
  mt_changed_row[1,] <- mt_changed_row[1,] * 9}
)

col_row |>
  mutate(expr = case_when(stringr::str_detect(expr, "col") ~ "by col",
                          TRUE ~ "by row"))  |>
  group_by(expr) |>
  summarise(`mean time (Î¼s)` = mean(time)/1000) |>
  knitr::kable() # about 4x faster to change the col than the row

ggplot2::autoplot(col_row)
```

We also looked briefly at alternative representation. The range operator is the best example of highly compact representations:

```{r}
obj_size(1:1000000) # approx size?
obj_size(1:2) == obj_size(1:1000000) # the range operator only stores the first and last values

obj_size(seq(1, 1000000)) # seq will use the same alternative representation...
obj_size(seq(1, 1000000, 1.0)) # unless you ask it to make a sequence with non-1L steps 
```

`object.size` has lots of interesting implications for lists as it only describes the size of the references, rather than the underlying objects:

```{r}
obj_size(rnorm(1e6)) # 8 mb
mill <- obj_size(rnorm(1e6)) 

obj_size(list(rnorm(1e6), rnorm(1e6), rnorm(1e6)))#??
obj_size(list(mill, mill, mill))#??

obj_size(tibble(a = mill, 
                b = mill,
                c = mill))
```

All strings are held in a common area of memory called the common string pool. This gives rise to a lot of interesting size consequence for vectors with shared strings:

```{r}
s1 <- c("the", "cat", "sat", "mat")
s2 <- c("the", "the", "the", "the")

obj_size(s1)
obj_size(s2)

ref(s1, character = TRUE)
ref(s2, character = TRUE)

obj_size(c(1,2,3,4)) # numeric vectors don't behave in the same way
obj_size(c(4,4,4,4))
```
